[
  {
    "objectID": "posts/post-with-code/index.html",
    "href": "posts/post-with-code/index.html",
    "title": "Data-first mentality.",
    "section": "",
    "text": "Calling Python “Excel on steroids without the UI” sells it short. But the framing has merit. Python, like Excel, is a tool to process data.\nThe term ‘programming language’ shapes how we view tools like Python. We often forget that languages are tools. Language turns thought into communication. It’s so good at this that we tend to confuse the words with the thoughts temselves. Thus we conflate our vocabulary with our identity\nThe same blind spot distorts how programmers view coding languages. To build great software, we should view code less like poetry and more like a campfire. There are efficient and inefficient ways to stack firewood, but the fire—not the wood—is what matters most.\nProgrammers often mistake mastery of syntax for mastery of software. We feel accomplished when we learn a new library or expression. But being a great linguist doesn’t make someone a great communicator. Likewise, great code doesn’t guarantee great software.\nSoftware revolves around handling data, and data is hard to control. First, you have to get the right data—maybe from users, or the internet. Then you have to transform that data into something useful—maybe a UI, or meaningful statistics.\nWhen we think about coding, many of us imagine building ‘things’. In reality, we’re automating and optimizing processes. Using Excel to make cell C1 divide cell A1 by cell B1 isn’t groundbreaking. But show a non-developer some resilient code that does the same, and they’ll think it’s magic.\n\nimport logging\nfrom typing import Union\n\nlogging.basicConfig(level=logging.INFO)\n\ndef divide_two_numbers(numerator: Union[int, float], denominator: Union[int, float]) -&gt; float:\n    \"\"\"Perform division between two numeric values.\n\n    Args:\n        numerator (Union[int, float]): The number to be divided.\n        denominator (Union[int, float]): The number to be divided by.\n\n    Returns:\n        float: The result of dividing `numerator` by `denominator`.\n\n    Raises:\n        TypeError: If either input is not a number.\n        ValueError: If attempting to divide by zero.\n    \"\"\"\n    logging.info(\"Initiating the division process.\")\n\n    # Type validation\n    if not isinstance(numerator, (int, float)):\n        raise TypeError(f\"Invalid type for 'numerator': {type(numerator).__name__}. Expected int or float.\")\n    if not isinstance(denominator, (int, float)):\n        raise TypeError(f\"Invalid type for 'denominator': {type(denominator).__name__}. Expected int or float.\")\n\n    # Check for division by zero\n    if denominator == 0:\n        logging.error(\"Attempted division by zero. This operation is undefined.\")\n        raise ValueError(\"Denominator cannot be zero.\")\n\n    logging.info(f\"Inputs validated: numerator={numerator}, denominator={denominator}. Proceeding with division.\")\n    result = numerator / denominator\n    logging.info(f\"Division completed. Result: {result}\")\n    return result\n\nnumerator = 10.0\ndenominator = 2.0\n\ntry:\n    division_result = divide_two_numbers(numerator, denominator)\n    print(division_result)\nexcept Exception as e:\n    logging.error(f\"An error occurred during division: {e}\")\n\nINFO:root:Initiating the division process.\nINFO:root:Inputs validated: numerator=10.0, denominator=2.0. Proceeding with division.\nINFO:root:Division completed. Result: 5.0\n\n\n5.0\n\n\nThis toy example illustrates how a simple task can look complex in code. The input and output of the Excel function and this Python function could be identical. But the Python code looks arcane. It carries a mystique that tends to become a source of inflated pride in coders.\nLearning a programming language takes significant effort. When you finally write good software, it feels like you’ve passed an initiation into an exclusive club. In a way, you have.\nBut remember, the code itself isn’t what matters most. The data does."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "about_me",
    "section": "",
    "text": "Writing about software, math, and music.\nNortheastern, Center for Inclusive Computing."
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!\n\nSince this post doesn’t specify an explicit image, the first image in the post will be used in the listing page of posts."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "giordano_rogers",
    "section": "",
    "text": "Semantic Similarity\n\n\n\n\n\n\nNLP\n\n\nmath\n\n\n\n\n\n\n\n\n\nJan 4, 2025\n\n\nGiordano Rogers\n\n\n\n\n\n\n\n\n\n\n\n\nFourier Series for Modeling Melody\n\n\n\n\n\n\nmusic\n\n\nmath\n\n\n\n\n\n\n\n\n\nJan 4, 2025\n\n\nGiordano Rogers\n\n\n\n\n\n\n\n\n\n\n\n\nGood technical writing.\n\n\n\n\n\n\nprogramming\n\n\n\n\n\n\n\n\n\nJan 2, 2025\n\n\nGiordano Rogers\n\n\n\n\n\n\n\n\n\n\n\n\nData-first mentality.\n\n\n\n\n\n\nprogramming\n\n\nphilosophy\n\n\n\n\n\n\n\n\n\nJan 2, 2025\n\n\nGiordano Rogers\n\n\n\n\n\n\n\n\n\n\n\n\nBase Case Behavior.\n\n\n\n\n\n\nprogramming\n\n\nphilosophy\n\n\n\n\n\n\n\n\n\nJan 2, 2025\n\n\nGiordano Rogers\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/base_case_behavior/index.html",
    "href": "posts/base_case_behavior/index.html",
    "title": "Data-first mentality.",
    "section": "",
    "text": "Base Case Behavior\nThe concept of base cases in inductive hypotheses are a good way to approach programming.\nAlways test the base case: the most simple version of what you’re trying to achieve.\nYou want to build a wrapper around an api?\nMake the simplest possible api call first.\nYou want to build your own REST API to interact with your database?\nBuild one that prints a simple “hello world” response first.\nAlwasy start simple.\nAlways start with the base case.\nFrom there, you have a foundation to reason about the rest of the sequence.\nNow I have a frame.\nIf I add this one small next step, I can it again.\nI can keep iterating slowly through the sequence of events until I reach the outcome I’m looking for.\nBut now I’m not looking blindly.\nBase case programming is prototyping.\nBut unlike the concept of protoyping, the term base case programming emphasizes two important things. First, is simplicity. In mathematical reasoning, the base case is always considered somewhat arbitrary, usually contained withing the definition of the proposition itself.\nConsider the following sequence: \\[\nx_n = 2x_{n-1} + x_{n-2} \\quad \\text{for} \\quad n \\geq 3\n\\]\nUse induction to prove that \\(a_{2n}\\) is even for all integers \\(n \\ge 1\\).\nWhen you first see a prolem like this, there’s no clear way to reason about.\nNow, if I give you the start of the sequence, you can start to build up an intuition.\n\\[\nx_1 = -1, \\quad x_2 = 0, \\quad x_n = 2x_{n-1} + x_{n-2} \\quad \\text{for} \\quad n \\geq 3\n\\]\nThe way we’d prove the conjecture formally, is by starting with these base cases, and reasoning up.\n\\[\nx_3 = 2(0) + (-1) = -1\nx_4 = 2(-1) + (0) = -2\nx_5 = 2(-2) + (-1) = -5\n\\]\nBut to prove the statement generally, we don’t have to show every step of the sequence.\nWe just have to show that the next step always follows the same pattern.\nAssume that \\(x_{2k}\\) is even for some integer \\(k \\ge 1\\). We can prove that \\(x_2(k+1)\\) is even, because:\n\\[\nx_{2(k+1)} = 2x_{2(k+1)-1} + x_{2(k+1)-2} = 2x_{k+1} + a_{2k}\n\\]\nSince \\(a_{2k}\\) is even, and $2a_{2k+1} must be even sice $a_{2K+1}\nIn this example, there\nThe base case is always"
  },
  {
    "objectID": "base_case_behavior.html",
    "href": "base_case_behavior.html",
    "title": "Base Case Behavior",
    "section": "",
    "text": "Base Case Behavior\nThe concept of base cases in inductive hypotheses are a good way to approach programming.\nAlways test the base case: the most simple version of what you’re trying to achieve.\nYou want to build a wrapper around an api?\nMake the simplest possible api call first.\nYou want to build your own REST API to interact with your database?\nBuild one that prints a simple “hello world” response first.\nAlwasy start simple.\nAlways start with the base case.\nFrom there, you have a foundation to reason about the rest of the sequence.\nNow I have a frame.\nIf I add this one small next step, I can it again.\nI can keep iterating slowly through the sequence of events until I reach the outcome I’m looking for.\nBut now I’m not looking blindly.\nBase case programming is prototyping.\nBut unlike the concept of protoyping, the term base case programming emphasizes two important things. First, is simplicity. In mathematical reasoning, the base case is always considered somewhat arbitrary, usually contained withing the definition of the proposition itself.\n%%latex\nx_0 = 0, x_1 = 4\nThe base case is always"
  },
  {
    "objectID": "posts/using-the-arxiv-api/index.html",
    "href": "posts/using-the-arxiv-api/index.html",
    "title": "Good technical writing.",
    "section": "",
    "text": "The first time I actually enjoyed reading a book that was somewhat technical was when I read the book “Thinking About Mathematics” by Stewart Shapiro.\nWhat stood about to me about his writing was…\nBut still, Shapiro’s book was more philosophical than mathematical.\nI went on to read some more technical books that I enjoyed. O’Reilly book publishers have some good stuff. I’ve found that an O’Reilly book with a lot of five star reviews, a compelling title, and a cool looking animal on the cover to be a good heuristic for choosing my next technical book to read."
  },
  {
    "objectID": "posts/generative_music/index.html",
    "href": "posts/generative_music/index.html",
    "title": "Fourier Series for Modeling Melody",
    "section": "",
    "text": "A function is mapping of an object in a set to some output.\nThe musical notes are a set.\nA musical scale is a more narrow set.\nAnd rhythms and progressions can be codified down to a generative algorithm.\nFor example, take the melody for “Mary Had a Little Lamb”\nEDCDEEEDDDEGGEDCDEEEEDDEDC\nCan we create a function f(x) that computes the proper note if we treat x as the note’s index in the sequence?\nWhat about a simpler harmony first.\n\n  \n  Your browser does not support the audio element.\n\nThis is a walk up and down the C major chord. We start at E, then up three half-notes to G, back to E, down three half-notes to C, and then back to E.\nIf we express each bar of a four bar loop as a zero indexed array, then we can model this melody as mathematically as the function:\n\\[\nf(x) = 4 + 3\\sin(\\frac{\\pi}{2}x)\n\\]\nOr, in python:\n\nfrom math import sin, pi\n\ndef egec(index):\n    note = 4 + 3 * sin((pi / 2) * index)\n    return round(note)\n\nnote_list = [egec(index) for index in range(8)]\nprint(note_list)\n\n[4, 7, 4, 1, 4, 7, 4, 1]\n\n\nAnd we can graph this melody like so:\n\n\n\nGraph of the EGEC melody function\n\n\nIt shouldn’t be surprising that we can graph simple melodies like this as sine curves. After all, the MIDI notes on my piano roll in Ableton Live look just like the graph:\n\n\n\nMIDI piano roll of EGEC melody\n\n\nWhat’s interesting about this is that any melody we can functionalize like this, we can generate programmatically.\nThink about the whole world of automated music we can make if we can define our melodic taste in such a formal way.\nNow obviously, this simple melody would get very boring after some time.\nLet’s return to thinking about the Mary Had A Little Lamb melody.\nHere are the notes again:\nEDCDEEEDDDEGGEDCDEEEEDDEDC\nHere it is as played on the piano:\n\n  \n  Your browser does not support the audio element.\n\nThis melody is not as periodic as the EGEC melody, but there’s still enough of a pattern to it that we can intuitively sense that there must be some way to map it to a function.\nLuckily, a similar logic applies.\nJust like we used a sin wave to model the transitions in the EGEC melody, we can combine several sin wavs to approximate a function that will get us our Mary Had A Little Lamb melody too.\nThis will involve using the power of the Fourier series.\nA Fourier series can approximate any periodic function by summing sine and cosine terms.\nEven though the Mary Had a Lamb melody isn’t periodic, we can “force” periodicity by repeating the sequence and using Fourier coefficients to approximate the pattern.\n\nfrom numpy import arange, linspace, cos, sin, mean\n\n# Define the melody as integers\nmelody = [4, 2, 0, 2, 4, 4, 4, 2, 2, 2, 4, 7, 7,\n          4, 2, 0, 2, 4, 4, 4, 4, 2, 2, 4, 2, 0]\nN = len(melody)  # Number of terms in the melody\nx_vals = arange(0, N)  # Melody indices\n\n# Extend melody for visualization\nrepeats = 3\nextended_melody = melody * repeats\nextended_x_vals = arange(0, N * repeats)\n\n# Compute Fourier series approximation\ndef fourier_series(x, num_terms=10):\n    a0 = mean(melody)  # Mean value (DC component)\n    approx = a0  # Start with the DC component\n    for n in range(1, num_terms + 1):\n        an = (2 / N) * sum(melody * \\\n          cos(2 * pi * n * x_vals / N))\n        bn = (2 / N) * sum(melody * \\\n          sin(2 * pi * n * x_vals / N))\n        approx += an * cos(2 * pi * n * x / N) + \\\n          bn * sin(2 * pi * n * x / N)\n    return approx\n\n# Generate Fourier approximation\nx_approx = linspace(0, N * repeats, 1000)  # Smooth x values\ny_approx = fourier_series(x_approx)\n\n# Generate discrete indices for approximation\ndiscrete_indices = arange(0, N * repeats)  # Integer indices\n\n# Compute Fourier series and round to nearest whole number\ny_discrete_approx = [round(fourier_series(x))\n                     for x in discrete_indices]\n\n# Print the first 16 approximated notes\nprint(\"First 16 Notes of Mary Had a Little Lamb\")\nprint(\"\\nFourier Approximation (Rounded):\")\nprint(y_discrete_approx[:16])\nprint(\"\\nOriginal Melody:\")\nprint(extended_melody[:16])\n\nFirst 16 Notes of Mary Had a Little Lamb\n\nFourier Approximation (Rounded):\n[4, 2, 0, 2, 4, 4, 4, 2, 2, 2, 4, 7, 7, 4, 2, 0]\n\nOriginal Melody:\n[4, 2, 0, 2, 4, 4, 4, 2, 2, 2, 4, 7, 7, 4, 2, 0]\n\n\nAnd we can view the graph of the approximated curve too:\n\n\n\nGraph of the Mary Had a Little Lamb melody\n\n\nAnd if we zoom in the graph a bit to see the first cycle of the melody:\n\n\n\nGraph of the first cycle of the Mary Had a Little Lamb melody\n\n\nAnd as we’d expect, we can see that it looks pretty similar to the piano roll of the midi notes for Mary Had a Little Lamb that I recorded in Ableton Live:\n\n\n\nMIDI piano roll for Mary Had a Little Lamb\n\n\nAgain though, this Mary Had a Little Lamb melody is very simple compared to the melodies in most of the music people tend to listen to.\nBut the beauty of the Fourier series is that we can create curves for many different melodies using this same technique, and then we can adjust the curves by changing a few parameters, and generate similar but novel melodies with our new adapted curves.\nAs a more advanced step, we could combine Fourier methods with neural networks to capture non-period and stylistic elements."
  },
  {
    "objectID": "buy_list.html",
    "href": "buy_list.html",
    "title": "Buy List",
    "section": "",
    "text": "Buy List\nincense\nblack, red, blue dry erease markers"
  },
  {
    "objectID": "notes/templates/tutorial.html",
    "href": "notes/templates/tutorial.html",
    "title": "Tutorial",
    "section": "",
    "text": "Choose a topic\nExplain it simply\nBuild something\nRefactor & share\n\n\n\n\n\n\n\n\n\n\n\n\n\nVoice: Friendly but authoritative.\nClarity: Simplify jargon unless necessary for depth.\nConciseness: 500-800 words.\nEngagement: Short paragraphs, lists, and subheadings."
  },
  {
    "objectID": "notes/templates/tutorial.html#style-consistency-checklist",
    "href": "notes/templates/tutorial.html#style-consistency-checklist",
    "title": "Tutorial",
    "section": "",
    "text": "Voice: Friendly but authoritative.\nClarity: Simplify jargon unless necessary for depth.\nConciseness: 500-800 words.\nEngagement: Short paragraphs, lists, and subheadings."
  },
  {
    "objectID": "notes/greatest_books.html",
    "href": "notes/greatest_books.html",
    "title": "giordano_rogers",
    "section": "",
    "text": "Thinking about Mathematics Total Freedom Good and Real Blood Meridian The Glass Bead Game Runaway Horses Beyond Good and Evil Essential Math for Data Science Ways of Seeing The Autobiography of Malcolm X"
  },
  {
    "objectID": "notes/cursed_dreams.html",
    "href": "notes/cursed_dreams.html",
    "title": "Cursed Dreams",
    "section": "",
    "text": "Cursed Dreams\n\n“People who design machines…. No matter how much they believe what they do is good, the winds of time eventually turn them into tools of industrial civilization. It’s never unscathed. They’re cursed dreams.”\n\n– Hayao Miyazaki"
  },
  {
    "objectID": "010325.html",
    "href": "010325.html",
    "title": "01/03/2025",
    "section": "",
    "text": "There is a sense of guilt I feel at the idea of not dedicating myself to ASI.\nThe guilt occurs on two levels.\nFirstly, I’d feel guilty for not contributing my energy to materializing a technology that would improve well being. If we could solve every medical, engineering, and social problem, the benefits would be tremendous.\nIf my effort could get us there even one day sooner, it would save thousands of people from trauma. And “my effort” here doesn’t need to imply that I invent AGI. My awareness being centered on anything is a multiplier for global attention. The conversations I have, the energy I put out, the communities I enliven with my participation—all of this has a butterfly effect which transforms the world.\nWhen I ask myself—what is the most important thing to work on?—the answer is ASI. And if the scaling hypothesis is false, and we need different algorithms to get us there, then it seems compelling to me to work on this.\nBut I’m far from a competent mathematician. But I could become one. Not a great, but at least competent.\nThis is where the ego enters the picture. My desire to be great steps in and says that whatever I dedicate my life to ought to be something that I can be great at. I don’t think that’s true objectively. But subjectively I do. From a broader perspective I don’t think my own greatness matters that much—greatness here meaning social greatness, greatness as social role. But individual greatness and social greatness are different. I can be great at being me, great at what I do, without being great within a narrow domain relative to others. You could picture this as being in the third quartile of competency at any given domain I involve myself in, but in the 1% when it comes to overall quality being. I use “quality of being” here rather than “quality of life” because the “being” I’m evoking is a being of action and assertion. The people who are in the 1% of being in the world are different than the 1% richest or the 1% happiest. This seems like a greater goal than narrow greatness. And yet society idolizes the narrowly great. I idolize the narrowly great.\nThe second reason I’d feel guilty is because this field will clearly be successful and I want to participate in its success. Yes, partially out of a desire to satisfy my desire for wealth, and also the gratification of being considered big-brained. It’s all shameful but it’s all real. But beyond that, there is a desire for the excitement of being part of this bubbling field. I want to talk with people about how to use AI to make the world better.\nMaking the world better feels so grand and amorphous that its not only hard to know what one is even implying in that phrase, but also to picture onesself as accomplishing such a feat. I do think the benefits in the medical field would be the most profound. I want to solve the mental and physical ailment problem. Imagine if we lived in a world where we understood the human body so well that none of the physical and mental ailments I or my loved ones have ever experienced were a thing of the past? It’s almost incomprehensible how much better the world could be.\nIt’s difficult grappling with the urge toward high-level thinking and low-level competency. I seem to be good at building things. I could be much better. But if I consider the teams I’ve been apart of over 2024, I recognize that I’m relatively good at holding many components in my mind. It’s hard, and most people aren’t good at it. I’m not the best. But it’s important to recognize that I’m already third quartile at this.\nDefinition: Artificial Super Intelligence is a machine learning system that can exponentially increase its ability to model and solve problems, including the problem of accelerating its own capacity to solve problems.\nConjecture: Artificial Super Intelligence will be achieved within twenty years.\nI think this conjecture is mostly based on excitement. It is exciting that transformers can derive statistical semantics and generatively model them.\n\n\nI have lived the last two years of my life in overall deferrment of gratification. I have been living for tomorrow. But in some ways I think it has been desructive to my identity. In some ways I find it harder to move through this world as an integrated individual. And I’m undecided whether to say one is delusionional to believethat integrated individuals exist at all, or to doubt it. At the very least, I have experienced my life dysphorically for its entirety, and I’d rather not.\nBut I mean this optimistically—I don’t think it’s a necessity. It’s something that I am inclined to, but I also see a vector leading toward a place of less disphoria and more synchronicity with my environment.\nMaybe this is wishful thinking—because I’m actually not sure what that vector is. I guess, pragmatically, it would mean focusing my energy outward, on others, instead of so much on myself. Of extending my hand to the world—inviting that associate out for a drink or a meal. Asking that girl out. Making that project I’m scared to make. But as I type all this the fantasy of it all becomes clear. It’s a projection of my identity onto an imaginary vision.\nAll things start with a vision. But still, I recognize the irreality of it.\n\n\n\nI want to master software building. I want to build things that are immediately useful. But I also want to contribute to stepping toward artificial super intelligence.\nIt seems there is still a lot of self-learning I need to do before I can get there. And probably the best use of my energy is in empowering myself and others to get to this goal.\nI feel conflicted about media, and academia, and entrepreneurship. But I think this is in part because I treat them all as though they are different vectors and this creates a tension that pulls me apart and inhibits my progress.\nIf I were to step all of these things in the same direction, and throw in my need for artistic fulfillment as well, it would be this:\nartistry -&gt;\nmedia -&gt; academia ———–| applied ai entrepreneurhip —-|\nIt feels like there’s not even a paradigm for what I’m trying to concretize in my mind.\nIt’s almost like software shamanism. Its a form of\n\n\n\nFundamentally, a high quality machine learning algorithm is domain agnositc. Maybe that’s wrong. But math itself certainly is domain agnostic. Not certianly, but apparently—although there are some gaps which we don’t seem to necessarily be able to fill with math—such as the realm of the psyche.\nWhat I’m trying to say is that I can be a pluralist if I have the right approach.\nMusic making is an algorithmic process that is very mathematizable. Storytelling, not so much. But it is not hard to imagine overlapping music, math, and AI.\nThe question is: do I even want to do that? Am I only compelled by music for egotistical reasons?\nI think moreso than anything, I desire to be a man on a mission. And for that, I need a dream.\nI was startled out of my last dream. And now I’m sleep walking.\nAs I sit here and think, I find my mind wandering to examples of others from which to model how I ought to act in the world—who I can be."
  },
  {
    "objectID": "010325.html#a-counter-position",
    "href": "010325.html#a-counter-position",
    "title": "01/03/2025",
    "section": "",
    "text": "I have lived the last two years of my life in overall deferrment of gratification. I have been living for tomorrow. But in some ways I think it has been desructive to my identity. In some ways I find it harder to move through this world as an integrated individual. And I’m undecided whether to say one is delusionional to believethat integrated individuals exist at all, or to doubt it. At the very least, I have experienced my life dysphorically for its entirety, and I’d rather not.\nBut I mean this optimistically—I don’t think it’s a necessity. It’s something that I am inclined to, but I also see a vector leading toward a place of less disphoria and more synchronicity with my environment.\nMaybe this is wishful thinking—because I’m actually not sure what that vector is. I guess, pragmatically, it would mean focusing my energy outward, on others, instead of so much on myself. Of extending my hand to the world—inviting that associate out for a drink or a meal. Asking that girl out. Making that project I’m scared to make. But as I type all this the fantasy of it all becomes clear. It’s a projection of my identity onto an imaginary vision.\nAll things start with a vision. But still, I recognize the irreality of it."
  },
  {
    "objectID": "010325.html#so-what-am-i-to-do",
    "href": "010325.html#so-what-am-i-to-do",
    "title": "01/03/2025",
    "section": "",
    "text": "I want to master software building. I want to build things that are immediately useful. But I also want to contribute to stepping toward artificial super intelligence.\nIt seems there is still a lot of self-learning I need to do before I can get there. And probably the best use of my energy is in empowering myself and others to get to this goal.\nI feel conflicted about media, and academia, and entrepreneurship. But I think this is in part because I treat them all as though they are different vectors and this creates a tension that pulls me apart and inhibits my progress.\nIf I were to step all of these things in the same direction, and throw in my need for artistic fulfillment as well, it would be this:\nartistry -&gt;\nmedia -&gt; academia ———–| applied ai entrepreneurhip —-|\nIt feels like there’s not even a paradigm for what I’m trying to concretize in my mind.\nIt’s almost like software shamanism. Its a form of"
  },
  {
    "objectID": "010325.html#fundamentally",
    "href": "010325.html#fundamentally",
    "title": "01/03/2025",
    "section": "",
    "text": "Fundamentally, a high quality machine learning algorithm is domain agnositc. Maybe that’s wrong. But math itself certainly is domain agnostic. Not certianly, but apparently—although there are some gaps which we don’t seem to necessarily be able to fill with math—such as the realm of the psyche.\nWhat I’m trying to say is that I can be a pluralist if I have the right approach.\nMusic making is an algorithmic process that is very mathematizable. Storytelling, not so much. But it is not hard to imagine overlapping music, math, and AI.\nThe question is: do I even want to do that? Am I only compelled by music for egotistical reasons?\nI think moreso than anything, I desire to be a man on a mission. And for that, I need a dream.\nI was startled out of my last dream. And now I’m sleep walking.\nAs I sit here and think, I find my mind wandering to examples of others from which to model how I ought to act in the world—who I can be."
  },
  {
    "objectID": "notes/buy_list.html",
    "href": "notes/buy_list.html",
    "title": "Buy List",
    "section": "",
    "text": "Buy List\nincense\nblack, red, blue dry erease markers"
  },
  {
    "objectID": "notes/notes/010325.html",
    "href": "notes/notes/010325.html",
    "title": "01/03/2025",
    "section": "",
    "text": "There is a sense of guilt I feel at the idea of not dedicating myself to ASI.\nThe guilt occurs on two levels.\nFirstly, I’d feel guilty for not contributing my energy to materializing a technology that would improve well being. If we could solve every medical, engineering, and social problem, the benefits would be tremendous.\nIf my effort could get us there even one day sooner, it would save thousands of people from trauma. And “my effort” here doesn’t need to imply that I invent AGI. My awareness being centered on anything is a multiplier for global attention. The conversations I have, the energy I put out, the communities I enliven with my participation—all of this has a butterfly effect which transforms the world.\nWhen I ask myself—what is the most important thing to work on?—the answer is ASI. And if the scaling hypothesis is false, and we need different algorithms to get us there, then it seems compelling to me to work on this.\nBut I’m far from a competent mathematician. But I could become one. Not a great, but at least competent.\nThis is where the ego enters the picture. My desire to be great steps in and says that whatever I dedicate my life to ought to be something that I can be great at. I don’t think that’s true objectively. But subjectively I do. From a broader perspective I don’t think my own greatness matters that much—greatness here meaning social greatness, greatness as social role. But individual greatness and social greatness are different. I can be great at being me, great at what I do, without being great within a narrow domain relative to others. You could picture this as being in the third quartile of competency at any given domain I involve myself in, but in the 1% when it comes to overall quality being. I use “quality of being” here rather than “quality of life” because the “being” I’m evoking is a being of action and assertion. The people who are in the 1% of being in the world are different than the 1% richest or the 1% happiest. This seems like a greater goal than narrow greatness. And yet society idolizes the narrowly great. I idolize the narrowly great.\nThe second reason I’d feel guilty is because this field will clearly be successful and I want to participate in its success. Yes, partially out of a desire to satisfy my desire for wealth, and also the gratification of being considered big-brained. It’s all shameful but it’s all real. But beyond that, there is a desire for the excitement of being part of this bubbling field. I want to talk with people about how to use AI to make the world better.\nMaking the world better feels so grand and amorphous that its not only hard to know what one is even implying in that phrase, but also to picture onesself as accomplishing such a feat. I do think the benefits in the medical field would be the most profound. I want to solve the mental and physical ailment problem. Imagine if we lived in a world where we understood the human body so well that none of the physical and mental ailments I or my loved ones have ever experienced were a thing of the past? It’s almost incomprehensible how much better the world could be.\nIt’s difficult grappling with the urge toward high-level thinking and low-level competency. I seem to be good at building things. I could be much better. But if I consider the teams I’ve been apart of over 2024, I recognize that I’m relatively good at holding many components in my mind. It’s hard, and most people aren’t good at it. I’m not the best. But it’s important to recognize that I’m already third quartile at this.\nDefinition: Artificial Super Intelligence is a machine learning system that can exponentially increase its ability to model and solve problems, including the problem of accelerating its own capacity to solve problems.\nConjecture: Artificial Super Intelligence will be achieved within twenty years.\nI think this conjecture is mostly based on excitement. It is exciting that transformers can derive statistical semantics and generatively model them.\n\n\nI have lived the last two years of my life in overall deferrment of gratification. I have been living for tomorrow. But in some ways I think it has been desructive to my identity. In some ways I find it harder to move through this world as an integrated individual. And I’m undecided whether to say one is delusionional to believethat integrated individuals exist at all, or to doubt it. At the very least, I have experienced my life dysphorically for its entirety, and I’d rather not.\nBut I mean this optimistically—I don’t think it’s a necessity. It’s something that I am inclined to, but I also see a vector leading toward a place of less disphoria and more synchronicity with my environment.\nMaybe this is wishful thinking—because I’m actually not sure what that vector is. I guess, pragmatically, it would mean focusing my energy outward, on others, instead of so much on myself. Of extending my hand to the world—inviting that associate out for a drink or a meal. Asking that girl out. Making that project I’m scared to make. But as I type all this the fantasy of it all becomes clear. It’s a projection of my identity onto an imaginary vision.\nAll things start with a vision. But still, I recognize the irreality of it.\n\n\n\nI want to master software building. I want to build things that are immediately useful. But I also want to contribute to stepping toward artificial super intelligence.\nIt seems there is still a lot of self-learning I need to do before I can get there. And probably the best use of my energy is in empowering myself and others to get to this goal.\nI feel conflicted about media, and academia, and entrepreneurship. But I think this is in part because I treat them all as though they are different vectors and this creates a tension that pulls me apart and inhibits my progress.\nIf I were to step all of these things in the same direction, and throw in my need for artistic fulfillment as well, it would be this:\nartistry -&gt;\nmedia -&gt; academia ———–| applied ai entrepreneurhip —-|\nIt feels like there’s not even a paradigm for what I’m trying to concretize in my mind.\nIt’s almost like software shamanism. Its a form of\n\n\n\nFundamentally, a high quality machine learning algorithm is domain agnositc. Maybe that’s wrong. But math itself certainly is domain agnostic. Not certianly, but apparently—although there are some gaps which we don’t seem to necessarily be able to fill with math—such as the realm of the psyche.\nWhat I’m trying to say is that I can be a pluralist if I have the right approach.\nMusic making is an algorithmic process that is very mathematizable. Storytelling, not so much. But it is not hard to imagine overlapping music, math, and AI.\nThe question is: do I even want to do that? Am I only compelled by music for egotistical reasons?\nI think moreso than anything, I desire to be a man on a mission. And for that, I need a dream.\nI was startled out of my last dream. And now I’m sleep walking.\nAs I sit here and think, I find my mind wandering to examples of others from which to model how I ought to act in the world—who I can be."
  },
  {
    "objectID": "notes/notes/010325.html#a-counter-position",
    "href": "notes/notes/010325.html#a-counter-position",
    "title": "01/03/2025",
    "section": "",
    "text": "I have lived the last two years of my life in overall deferrment of gratification. I have been living for tomorrow. But in some ways I think it has been desructive to my identity. In some ways I find it harder to move through this world as an integrated individual. And I’m undecided whether to say one is delusionional to believethat integrated individuals exist at all, or to doubt it. At the very least, I have experienced my life dysphorically for its entirety, and I’d rather not.\nBut I mean this optimistically—I don’t think it’s a necessity. It’s something that I am inclined to, but I also see a vector leading toward a place of less disphoria and more synchronicity with my environment.\nMaybe this is wishful thinking—because I’m actually not sure what that vector is. I guess, pragmatically, it would mean focusing my energy outward, on others, instead of so much on myself. Of extending my hand to the world—inviting that associate out for a drink or a meal. Asking that girl out. Making that project I’m scared to make. But as I type all this the fantasy of it all becomes clear. It’s a projection of my identity onto an imaginary vision.\nAll things start with a vision. But still, I recognize the irreality of it."
  },
  {
    "objectID": "notes/notes/010325.html#so-what-am-i-to-do",
    "href": "notes/notes/010325.html#so-what-am-i-to-do",
    "title": "01/03/2025",
    "section": "",
    "text": "I want to master software building. I want to build things that are immediately useful. But I also want to contribute to stepping toward artificial super intelligence.\nIt seems there is still a lot of self-learning I need to do before I can get there. And probably the best use of my energy is in empowering myself and others to get to this goal.\nI feel conflicted about media, and academia, and entrepreneurship. But I think this is in part because I treat them all as though they are different vectors and this creates a tension that pulls me apart and inhibits my progress.\nIf I were to step all of these things in the same direction, and throw in my need for artistic fulfillment as well, it would be this:\nartistry -&gt;\nmedia -&gt; academia ———–| applied ai entrepreneurhip —-|\nIt feels like there’s not even a paradigm for what I’m trying to concretize in my mind.\nIt’s almost like software shamanism. Its a form of"
  },
  {
    "objectID": "notes/notes/010325.html#fundamentally",
    "href": "notes/notes/010325.html#fundamentally",
    "title": "01/03/2025",
    "section": "",
    "text": "Fundamentally, a high quality machine learning algorithm is domain agnositc. Maybe that’s wrong. But math itself certainly is domain agnostic. Not certianly, but apparently—although there are some gaps which we don’t seem to necessarily be able to fill with math—such as the realm of the psyche.\nWhat I’m trying to say is that I can be a pluralist if I have the right approach.\nMusic making is an algorithmic process that is very mathematizable. Storytelling, not so much. But it is not hard to imagine overlapping music, math, and AI.\nThe question is: do I even want to do that? Am I only compelled by music for egotistical reasons?\nI think moreso than anything, I desire to be a man on a mission. And for that, I need a dream.\nI was startled out of my last dream. And now I’m sleep walking.\nAs I sit here and think, I find my mind wandering to examples of others from which to model how I ought to act in the world—who I can be."
  },
  {
    "objectID": "posts/semantic_similarity/index.html",
    "href": "posts/semantic_similarity/index.html",
    "title": "Semantic Similarity",
    "section": "",
    "text": "Part of why natural language processing appeals to me is the prospect of being able to compare two bodies of text mathematically.\nLately I’ve been building a an app that generates newsletter summarizations of emerging research.\nBut I’ve been asking myself how I can improve the paper filtering.\nAs of now, let’s say on a given day my app collects 100 papers from my research field.\nEven if all of these papers were summarized to a single sentence, I wouldn’t want to read all that.\nSo we need a way to automate the selection process, so that the three to five papers I see when I open up my email, are ones that I’m actually interested in.\nOne very simply approach would be to keep a list of keywords, and to check if any of the papers have abstracts that contain one of my keywords.\nAn issue with this is the problem of synonyms.\nWhat if I’m very interested in signal processing for music, and I decide to use the keywords\n\ndef keyword_search(\n    abstracts, keywords = [\"signal processing\", \"music\"]\n    ):\n    selected_abstracts = []\n    for abstract in abstracts:\n        for keyword in keywords:\n            if keyword in abstract.strip().lower():\n                selected_abstracts.append(abstract)\n    return selected_abstracts\n\nLet’s say an amazing new paper drops introducing a revolutionary new algorithm for musical signal processing, but the abstract only uses the common acronym DSP, for digital signal processing, rather than the whole word? What if instead of “music” they use synonys like “melody” or “instrumental”?\nIn that case, my simple string search method for selection wouldn’t work.\nAlthough the keyword search technically does fall under the branch of natural language processing, it is a very rudimentary approach and we have much better ways to perform this task.\nThe most common method currently is cosine similarity.\nThis involves converting two pieces of texts you want to compare into their own vector representaitons using LLM embeddings, and then computing the angle between the two vectors.\nThe mathematical formula for cosine similarity:\n\\[\n\\cos(\\theta) = \\frac{\\mathbf{a} \\cdot \\mathbf{b}}{ \\lVert \\mathbf{a} \\rVert \\lVert \\mathbf{b} \\rVert}\n\\]\nIn python:\n\nfrom numpy import dot, linalg\n\ndef cosine_similarity(a, b):\n  a_dot_b = dot(a, b)\n  a_norm = linalg.norm(a)\n  b_norm = linalg.norm(b)\n  return a_dot_b / (a_norm * b_norm)\n\nImplementation is stripped down for readability and teaching purposes, but fundamentally this is the essence of cosine similarity. It is surprising how much can be achieved with such a simple function.\nAs a toy example, consider we have three simplified vectors that represent three words.\n\nfrom numpy import random\n\ndog = random.normal(9, 0.1, 10)\ncat = random.normal(9, 0.1, 10)\nchocolate = random.normal(-1, 0.1, 10)\n\nIn practice, these vectors would be much longer, and we may be comparing whole paragraphs or documents rather than just single words. But we can look at this example and, both in language and in math, intuit that the first two terms are more similar than to eachother than either is to the third.\nUsing our cosing similarity function, we can calcualte this similarity.\n\nfrom numpy import dot, linalg, random\n\ndef cosine_similarity(a, b):\n  a_dot_b = dot(a, b)\n  a_norm = linalg.norm(a)\n  b_norm = linalg.norm(b)\n  return a_dot_b / (a_norm * b_norm)\n\nrandom.seed(69)\ndog = random.normal(9, 0.1, 10)\ncat = random.normal(9, 0.1, 10)\nchocolate = random.normal(-1, 0.1, 10)\n\nprint(\"Similarity between 'cat' and 'dog':\")\nprint(cosine_similarity(cat, dog))\nprint(\"\\nSimilarity between 'cat' and 'chocolate':\")\nprint(cosine_similarity(cat, chocolate))\nprint(\"\\nSimilarity between 'dog' and 'chocolate':\")\nprint(cosine_similarity(cat, chocolate))\n\nSimilarity between 'cat' and 'dog':\n0.9998795270450233\n\nSimilarity between 'cat' and 'chocolate':\n-0.9948113184001908\n\nSimilarity between 'dog' and 'chocolate':\n-0.9948113184001908\n\n\nIf we extend this logic out to the comparison between research paper abstracts, and my list of keywords, then we wouldn’t necessarily need the keywords themselves to be present in the text. All we would need is for the semantic meaning of the words in the text to be close enough to the semantics of my keywords so that the text is selected for as relevant, relative to all the other abstracts I collected on a given day.\nBut even though cosine similarity is the most popular tool for this job, it isn’t the only way. And maybe not even the best way.\nAnother method is to find the Euclidean distance,\nIn math notation, this is represented as:\n\\[\nd = \\sqrt{\\sum_{i=1}^{n}(a_i - b_i)^2}\n\\]\nAnd in python:\n\nfrom numpy import sqrt\n\ndef euclidean_distance(a, b):\n  sum = 0\n  for a_i, b_i in zip(a, b):\n    sum += (a_i - b_i) ** 2\n  return sqrt(sum)\n\nLet’s see how this function performs on our cat, dog, and chocolate vectors:\n\nfrom numpy import dot, linalg, sqrt, random\n\ndef cosine_similarity(a, b):\n  a_dot_b = dot(a, b)\n  a_norm = linalg.norm(a)\n  b_norm = linalg.norm(b)\n  return a_dot_b / (a_norm * b_norm)\n\ndef euclidean_distance(a, b):\n  sum = 0\n  for a_i, b_i in zip(a, b):\n    sum += (a_i - b_i) ** 2\n  return sqrt(sum)\n\nrandom.seed(69)\ndog = random.normal(9, 0.1, 10)\ncat = random.normal(9, 0.1, 10)\nchocolate = random.normal(-1, 0.1, 10)\n\nprint(\"\\nDistance between 'cat' and 'dog':\")\nprint(euclidean_distance(cat, dog))\nprint(\"\\nDistance between 'cat' and 'chocolate':\")\nprint(euclidean_distance(cat, chocolate))\nprint(\"\\nDistance between 'dog' and 'chocolate':\")\nprint(euclidean_distance(cat, chocolate))\n\n\nDistance between 'cat' and 'dog':\n0.531369027749265\n\nDistance between 'cat' and 'chocolate':\n31.609471832084054\n\nDistance between 'dog' and 'chocolate':\n31.609471832084054\n\n\nAgain this makes sense. We can see that the distance between ‘cat’ and ‘dog’ is relatively small, wheras the distances between each word and ‘chocolate’ is relatively large.\nBut so far we’ve been testing these algorithms on very simple data. Each of these vectors has only ten dimensions.\nHow would these algorithms hold up with realistic data? For example, vector embeddings generated with OpenAI’s embeddings model create vectors with 1536 dimension.\nAgain we’ll use a hack to get us there for demonstration purposes. Let’s change these ten dimensional vectors into 1500-dimensional vectors.\n\nfrom numpy import dot, linalg, sqrt, random\n\ndef cosine_similarity(a, b):\n  a_dot_b = dot(a, b)\n  a_norm = linalg.norm(a)\n  b_norm = linalg.norm(b)\n  return a_dot_b / (a_norm * b_norm)\n\ndef euclidean_distance(a, b):\n  sum = 0\n  for a_i, b_i in zip(a, b):\n    sum += (a_i - b_i) ** 2\n  return sqrt(sum)\n\nrandom.seed(69)\ndog = random.normal(9, 0.1, 1500)\ncat = random.normal(9, 0.1, 1500)\nchocolate = random.normal(-1, 0.1, 1500)\n\nprint(\"Similarity between 'cat' and 'dog':\")\nprint(cosine_similarity(cat, dog))\nprint(\"\\nSimilarity between 'cat' and 'chocolate':\")\nprint(cosine_similarity(cat, chocolate))\nprint(\"\\nSimilarity between 'dog' and 'chocolate':\")\nprint(cosine_similarity(cat, chocolate))\n\nprint(\"\\nDistance between 'cat' and 'dog':\")\nprint(euclidean_distance(cat, dog))\nprint(\"\\nDistance between 'cat' and 'chocolate':\")\nprint(euclidean_distance(cat, chocolate))\nprint(\"\\nDistance between 'dog' and 'chocolate':\")\nprint(euclidean_distance(cat, chocolate))\n\nSimilarity between 'cat' and 'dog':\n0.9998746586092114\n\nSimilarity between 'cat' and 'chocolate':\n-0.9950888019421268\n\nSimilarity between 'dog' and 'chocolate':\n-0.9950888019421268\n\nDistance between 'cat' and 'dog':\n5.52021942675591\n\nDistance between 'cat' and 'chocolate':\n387.32715847990386\n\nDistance between 'dog' and 'chocolate':\n387.32715847990386\n\n\nNow let’s use some statistical methods to see how the quality of our low-dimensional similarity/distance scores, and our high-dimensional similarity/distance scores stack up.\n\nfrom numpy import (\n  corrcoef, dot, linalg, sqrt,\n  random, std, var, sqrt\n)\n\ndef cosine_similarity(a, b):\n  a_dot_b = dot(a, b)\n  a_norm = linalg.norm(a)\n  b_norm = linalg.norm(b)\n  return a_dot_b / (a_norm * b_norm)\n\ndef euclidean_distance(a, b):\n  sum = 0\n  for a_i, b_i in zip(a, b):\n    sum += (a_i - b_i) ** 2\n  return sqrt(sum)\n\ndef diem(a, b, v_min, v_max, n_dim):\n    ed = sqrt(sum((ai - bi)**2 for ai, bi in zip(a, b)))\n    e_d = sqrt(n_dim) * (v_max - v_min) / 6  # Expected distance\n    sigma_ed = sqrt((v_max - v_min)**2 / 12)\n    return (v_max - v_min) / sigma_ed**2 * (ed - e_d)\n\n# Generate random vectors and compute metrics\nrandom.seed(69)\ndog = random.normal(9, 0.1, 1500)\ncat = random.normal(9, 0.1, 1500)\nchocolate = random.normal(-1, 0.1, 1500)\n\ncosine_cat_dog = cosine_similarity(cat, dog)\neuclidean_cat_dog = euclidean_distance(cat, dog)\ndiem_cat_dog = diem(cat, dog, -1, 9, 1500)\n\nprint(f\"Cosine Similarity: {cosine_cat_dog}\")\nprint(f\"Euclidean Distance: {euclidean_cat_dog}\")\nprint(f\"DIEM: {diem_cat_dog}\")\n\nCosine Similarity: 0.9998746586092114\nEuclidean Distance: 5.52021942675591\nDIEM: -70.83540361204122"
  }
]